- 구구의 JVM, 스레드 강의
- 구구의 퀘스트 3개

무엇을 관찰했나요? 이 퀘스트의 핵심 관찰 사항을 구체적으로 기록해보세요:
- **Thread 생성 방식에 대한 관찰:** Thread 클래스 상속과 Runnable 인터페이스 구현 방식에서 어떤 코드 구조의 차이점을 발견했나요? 두 방식 모두 동일한 결과를 만들어냈지만, 어떤 차이점이 있었는지 구체적으로 적어보세요. Thread 클래스 상속 방식은 Thread를 extends해서 구현했고, Runnable 인터페이스 구현 방식은 Runnable을 implements하고 그것을 다시 Thread로 객체로 생성했습니다.
- **동시성 문제에 대한 관찰:** synchronized 키워드를 추가하기 전의 sum 값이 정확히 얼마였나요? 1000개의 작업을 실행했는데 왜 그보다 작은 결과가 나왔을까요?: 972
- **스레드 풀 동작에 대한 관찰:** FixedThreadPool의 poolSize와 queueSize는 각각 몇이었나요? CachedThreadPool의 값들은 어떻게 달랐나요? 이 숫자들의 차이가 실제 애플리케이션에서 어떤 의미를 가질까요?: FixedThreadPool의 poolSize는 2, queueSize는 1 이었습니다. CachedThreadPool의 경우 PoolSize 3, queueSize 0 이었습니다. 


관찰한 현상에 대해 궁금한 점을 질문으로 만들어보세요
- 질문 1: `newFixedThreadPool` 과 `newCachedThreadPool`의 차이
	- 답변: newFixedThreadPool은 스레드 개수가 2개로 고정되어 있다. 따라서 3개의 작업을 시작하면 poolSize = 2, queeSize = 1이 된다. (실행 작업 2개, 대기 작업 1개이기 때문) newCachedThreadPool은 필요할때마다 스레드를 새로 만들고, 쓰지 않는 스레드는 일정 시간 이후 제거하는 스레드 풀이다. 따라서 요청이 갑자기 몰릴 때 빠르게 스레드를 늘려서 처리할 수 있고, 자원 낭비를 막을 수 있다. 다만 제한이 없으므로 부하가 지속될 경우 주의해야 한다.

---

- **일반 실행과 디버거 조작의 극명한 차이:** 평상시 실행에서는 테스트가 거의 항상 성공했는데, 디버거로 타이밍을 조작했을 때는 어떤 결과가 나왔나요? 이런 차이가 나타나는 이유가 무엇이라고 생각하시나요?: 디비거가 스레드를 브레이크 포인트에 정지시켜주기 때문에
- race condition이 발생하는 정확한 순간: 두 스레드가 모두 users.add(user) 에 도달할 수 있었던 이유는 무엇인가요? 각 스레드가 중복 체크를 수행한 시점에서 users 리스트의 상태는 어땠나요?: 읽고 -> 쓰기때문에, 아직 두 스레드 모두 쓰지 않은 상태에서 중복 체크를 수행했다. 따라서 users 리스트는 비어있었다.
- **시간 조작의 의미:** 디버거를 사용해서 스레드 실행을 일시정지시키는 것이 실제 운영 환경에서는 어떤 상황에 해당한다고 생각하시나요? 서버 부하, 네트워크 지연, 가비지 컬렉션 등이 유사한 효과를 만들어낼 수 있을까요?: 네. 서버 부하 상황에서 특정 스레드가 느려질 수 있기 때문에 이런 효과가 만들어질 수 있을 것 같습니다. 현재는 아니지만, 중복 체크 여부를 다른 서비스에 네트워크를 통해 물어본다면. 네트워크 지연도 문제가 될 수 있습니다.

- 질문 1: GC로 인해서도 이런 상황이 발생될 수 있을까?
	- 네. JVM이 GC 같은 특정 작업을 수행하기 위해, 모든 스레드를 중지하는 Stop-The-World가 발생할 수 있습니다. 이게 해당 상황을 재현하는 원인이 될 수 있습니다. 
- 왜 Stop-The-World가 발생하는가?
	- GC는 "힙 메모리에서 어떤 객체가 살아있는지/죽었는지"를 정확히 판단해야 합니다. 만약 애플리케이션 스레드가 동시에 실행되면서 객체 참조를 바꾼다면, GC가 잘못된 판단을 할 수 있습니다. 따라서 Stop-The-World 가 발생합니다.
- 질문 2: 그러면, 이걸 방어하기 위해서는 어떻게 코딩해야 할까?
	- 읽기 -> 쓰기 패턴 시 락 걸기
	- synchronized
	- CAS(ConcurrentHashMap.putIfAbsent, computeIfAbsent, Atomic*)
	- DB에 락 위임
	- 단일 작성자 패턴 (하나의 스레드만 쓰기, 나머지는 모두 읽기)
	- 등...


---


**무엇을 관찰했나요?**
1단계 기본 설정 결과:

- application.yml의 현재 설정값: threads.max = 2, accept-count = 1, max-connections = 1
- 테스트 결과: 실패
- App 콘솔에 출력된 "http call count" 숫자: 2
- assertThat에서 예상한 값(2)과 실제 결과의 일치 여부: 일치하지 않음

threads.max를 5로 변경했을 때:

- 테스트 결과: (성공/실패) : 실패
- App 콘솔의 "http call count" 숫자: 2
- 기본 설정 대비 변화: 동일

accept-count를 5로 변경했을 때:

- 테스트 결과: (성공/실패): 실패
- App 콘솔의 "http call count" 숫자: 3
- 로그 출력 시간 간격: 순차적 간격

max-connections를 5로 변경했을 때:

- 테스트 결과: (성공/실패): 실패
- App 콘솔의 "http call count" 숫자: 10
- 이전 두 실험과 비교한 결과: 로그 출력 시간이 5개 단위로 동시.

## ❓ 나만의 탐구 질문 만들기
- 질문 1: 만약 동시 요청 개수를 100개로 늘린다면 어떻게 될까?
		- 동시 요청 개수(스레드)를 100개로 늘린다면, 서버의 threads.max만큼 스레드가 돌아가다가, 이후는 accept-count만큼 큐에 대기한다. 나머지는 타임아웃, 연결 거부가 발생한다.
- 질문 2: 왜 threads.max보다 많은 요청이 와도 서버가 죽지 않을까?
	- 넘어온 요청을 무작정 스레드로 실행하지 않고, max를 넘으면 queue에 대기시키고, queue도 넘으면 연결을 거부한다. 따라서 서버는 죽지 않는다.
- 질문 3: accept-count와 max-connections의 차이점은 정확히 무엇일까?
	- accept-count는 threads.max를 넘겨서 더 이상 스레드를 생성할 수 없을 때, 스레드를 대기시켜놓는 수를 말한다.
- 질문 4: threads.max와 max-connections의 차이
	- threads.max 는 최대 스레드 수를 말하고, max-connections는 동시에 할 수 있는 TCP 연결 수를 말한다.