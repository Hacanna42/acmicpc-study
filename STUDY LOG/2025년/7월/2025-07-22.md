- 프론트엔드 nginx 설정 완료
- nginx certbot conflict 이슈 해결
- cloudfront 설정
- 로컬에서 브라우저에 업로드 할 때와, S3에서 다운로드 받을 때의 painting 비용 차이 분석


오늘 로컬에서 브라우저에 업로드 한 사진들과, S3에서 다운로드 받은 사진들의 스크롤 버벅임 차이가 있어서 엄청 열심히 알아봤다.

## 문제 상황

- `사진 업로드 화면`에서, 클라이언트가 브라우저에 로드한 로컬 사진들은 스크롤을 아무리 해도 렉이 걸리지 않음.
- 하지만, `스페이스 관리자 화면`에서 S3 에서 다운로드 하는 사진들은 **다운로드가 모두 완료된 사진임에도 불구하고** 스크롤을 하면 다시 사진이 로딩되는 현상을 관찰함.

## 생각의 흐름

- S3를 통해 다운로드 된 사진은 브라우저의 캐시에 저장된다.
- 그러면 로컬에 저장되어 있는 것과 다름이 없는데 왜 사진 로딩 차이가 발생하는가?

### 실험 1

- 설마, 캐시가 최신 상태인지 확신할 수 없으니 `Cache-Validation` 비용이 드나? `304 Not Modified`를 확인하고 로드하나?
- S3 오브젝트들 캐시 1년 지나도 만료 안되게 설정하고 돌려봐야징
- 결과 동일

### 실험 2

- 설마, S3에 CORS 정책이 설정되어 있지 않기 때문에, 이미지가 오염됐다고 가정하고 수비적으로 로드하나?
- S3 오브젝트들 CORS 정책 설정하고 돌려봐야징
- 결과 동일

### 실험 3

- 브라우저가 이미지 캐시를 저장할 때, .jpeg 같은 형태로 저장하는 게 아니라 `바이너리 데이터` 형태로 저장한다.
- 따라서 이미지를 다시 렌더링하려면 `바이너리 데이터` 를 `.jpeg` 등의 포맷으로 `디코딩` 해야하지 않나?
- 그러면 이미 디코딩이 완료된 포맷 `(.jpeg / .heic)` 등과 속도 차이가 날 수 있을 것 같다
- 결론: 아님.. 바이너리 데이터는 이미 해당 포맷임 (확장자만 없는거임)

### 가추한 결론

- 웹 브라우저는 **렌더링 직전에 RGBA 픽셀 버퍼로 변환**하고, GPU에 업로드해서 화면에 그린다.
- 즉 디코딩은 로컬이든 S3든 항상 필요하다. 단 이미 `GPU texture(캐시)`에 남아있으면 스킵할 수 있다.
- 그렇다면 로컬 사진과 S3 사진을 띄움에 있어서 `GPU texture 캐시` 지속 시간이 다르다면 이러한 차이가 발생할 수 있다.
- 왜냐면 화면에 띄워진 텍스처는 브라우저 내부의 메모리 캐시로 유지되는데, 이 텍스처 캐시는 우리가 통제하는 것이 아니라 브라우저가 언제든 버릴 수 있기 때문이다.
- 브라우저가 로컬 업로드 이미지는 GPU에 오래 유지할 가능성이 높다. 네트워크에서 온 이미지는 가시성 기준으로 GPU 캐시에서 제거 할 가능성이 있다.

## **🔍 부가적 증거**

- Chromium 내부에는 image decode cache, GPU memory budget, EvictionPolicy 등이 존재하며,
- **Blob URL로 올린 이미지**는 메모리 주소가 명확히 존재하기 때문에 texture eviction 우선순위에서 낮게 분류된다.

### Gemini의 의견

```java
네, 공유해주신 "가추한 결론"에 대해 제 생각을 말씀드리겠습니다.
결론부터 말씀드리면, 그 결론이 거의 정확한 정답에 가깝다고 생각합니다

* 브라우저가 화면에 이미지를 표시하려면, 압축된 파일(JPEG, PNG 등)을
	디코딩하여 픽셀 데이터(예: RGBA 비트맵)로 변환해야 합니다.
* 이 디코딩된 비트맵은 GPU가 처리할 수 있는 텍스처(Texture) 형태로
	GPU 메모리에 업로드됩니다. 이 과정이 실제로 화면에 그림을 그리는 단계입니다.
* 이 디코딩 과정은 CPU를 사용하며, 비용이 상당히 비싼 작업입니다.
  따라서 브라우저는 한번 디코딩한 결과(텍스처)를 GPU 메모리 캐시에 유지하여 재사용하려고 합니다.

핵심: 캐시 박탈 정책 (Eviction Policy)
* GPU 메모리는 한정된 자원입니다. 브라우저는 수많은 탭과 이미지,
  애니메이션을 관리해야 하므로 GPU memory budget을 가지고 있습니다.
* 스크롤 등으로 이미지가 화면 밖으로 사라지면, 브라우저는 메모리
  확보를 위해 해당 이미지의 GPU 텍스처를 캐시에서 제거(evict)할 수 있습니다.
* 사용자께서 내린 결론의 가장 중요한 부분은, 브라우저가 "로컬 파일"과 "네트워크 리소스"에 대해
다른 캐시 박탈 정책을 적용할 가능성이 매우 높다는 것입니다.  

* 로컬 사진 (사진 업로드 화면):
* 사용자가 <input type="file">로 로컬 파일을 선택하면, 브라우저는
         보안상의 이유로 실제 파일 경로(C:\\...)를 스크립트에 노출하지
         않습니다.
       * 대신 개발자는 URL.createObjectURL(file)을 사용하여 blob:http://...
         형태의 URL을 생성하고, 이를 <img> 태그의 src로 사용합니다.
       * 이 Blob URL은 네트워크 주소가 아니라, 브라우저 메모리에 이미
         올라와 있는 데이터 덩어리(Blob)에 대한 직접적인 포인터입니다.
       * 브라우저 입장에서 이 리소스는 "매우 안정적이고 비용이 저렴하며,
         항상 메모리에 존재함"을 인지합니다. 따라서 이 Blob을 기반으로
         생성된 GPU 텍스처는 캐시에서 제거될 우선순위가 매우 낮습니다 (low
         eviction priority).
         
        [주석 - 히스타]
        좀 더 정리하자면, 데이터의 안정성보다는 브라우저에게 전달되는
        데이터의 출처(origin)와 맥락(context)이 더 중요함. 브라우저 입장에서
        S3 URL은 (`https://...`):  저기 멀리 있는 외부 주소고,
        Blob URL(로컬 파일) (`blob:...`): 은 내부 주소(메모리 포인터) 이기 때문에.
        조금 더 중요하다고 판단하고 GPU Texture 을 늦게 파기하는 것일 가능성 있음.
         
           * S3 사진 (스페이스 관리자 화면):
       * 이 이미지의 src는 https://... 형태의 네트워크 URL입니다.
       * 비록 디스크 캐시(HTTP Cache)에 저장되어 있더라도, 브라우저는 이
         리소스를 근본적으로 "네트워크를 통해 가져온 것"으로 인식합니다.
       * GPU 메모리가 부족해지면, 브라우저는 "이 텍스처는 제거하더라도,
         필요하면 (네트워크보다는 빠른) 디스크 캐시에서 원본 파일을 다시
         읽어와 디코딩하면 된다"고 판단할 수 있습니다.
       * 따라서 Blob URL로 로드된 이미지보다 GPU 텍스처가 캐시에서 제거될
         우선순위가 더 높습니다 (higher eviction priority).
         
           이것이 바로 스크롤을 다시 올렸을 때, S3 이미지는 GPU 텍스처가 이미
  제거되어 비싼 디코딩 과정을 다시 거치기 때문에 버벅임(재로딩처럼 보이는
  현상)이 발생하는 이유입니다.
  
  해결법:   방법: S3 URL을 직접 <img>의 src에 넣지 말고, JavaScript를 사용해 해당
  이미지를 fetch로 다운로드한 후 Blob으로 변환하고, URL.createObjectURL()로
   Blob URL을 만들어 src에 넣어주는 것입니다.
```

---

# 팀원 공유용 결론

```java
[공유] S3 이미지 스크롤 시 발생하는 렌더링 지연 현상 분석 및 해결 방안

  안녕하세요, 여러분.

  스페이스 관리자 화면에서 S3 이미지를 스크롤할 때 발생하는 렌더링 지연
  현상에 대해 분석한 내용을 공유합니다.

  문제 현상

   - 로컬 업로드 이미지: 사용자가 직접 업로드한 로컬 사진들은 스크롤 시
     지연 현상 없이 부드럽게 표시됩니다.
   - S3 다운로드 이미지: S3에서 로드한 이미지들은 최초 로딩이
     완료되었음에도 불구하고, 화면 밖으로 나갔다가 다시 스크롤하여
     돌아오면 순간적으로 재로딩되는 듯한 버벅임(Jank)이 발생합니다.

  원인 분석

  처음에는 HTTP 캐시나 CORS 정책 문제로 접근했지만, 해당 설정 변경
  후에도 현상이 동일하여 더 깊은 원인을 분석했습니다.

  문제의 핵심은 브라우저의 렌더링 파이프라인과 GPU 메모리 관리 방식에
  있었습니다.

   1. 이미지 렌더링 과정과 '디코딩' 비용
       * 브라우저가 화면에 이미지를 그리려면, 원본 파일(JPEG, PNG 등)을
         디코딩(Decoding)하여 GPU가 이해할 수 있는 픽셀 데이터(RGBA
         비트맵)로 변환해야 합니다.
       * 이 디코딩 과정은 CPU 리소스를 소모하는, 상대적으로 비용이 매우
         비싼 작업입니다.

   2. GPU 텍스처 캐시의 역할
       * 브라우저는 이 비싼 디코딩 과정을 반복하지 않기 위해, 한번
         디코딩된 픽셀 데이터를 GPU 메모리(VRAM)에 텍스처(Texture) 형태로
         캐싱해 둡니다.
       * 이미지가 다시 화면에 표시될 때 이 캐시를 재사용하면, 디코딩
         과정을 건너뛰므로 매우 빠르게 렌더링할 수 있습니다.

  핵심 원인: 리소스 종류에 따른 '캐시 박탈 정책(Eviction Policy)'의 차이

  GPU 메모리는 한정된 자원이므로, 브라우저는 자체적인 Memory Budget에
  따라 스크롤 등으로 화면에서 사라진 이미지의 GPU 텍스처를 캐시에서
  제거(Evict)합니다.

  이때, 브라우저는 리소스의 출처에 따라 캐시 제거 우선순위를 다르게
  책정합니다.

   * 로컬 파일 (`Blob URL`)의 경우:
       * <input type="file">로 선택된 로컬 파일은 URL.createObjectURL()을
         통해 blob:http://... 형태의 URL로 변환됩니다.
       * 이 URL은 네트워크 주소가 아닌, 브라우저 메모리 내 데이터(Blob)를
         직접 가리키는 포인터입니다.
       * 브라우저는 이를 '신뢰할 수 있는 애플리케이션의 내부 상태'로
         간주하여, 해당 GPU 텍스처의 캐시 제거 우선순위를 매우 낮게(Low
         Eviction Priority) 설정합니다.

   * S3 이미지 (`https://...`)의 경우:
       * 이 이미지는 https:// URL을 통해 로드된 '네트워크 리소스'로
         인식됩니다.
       * 비록 디스크 캐시에 저장되어 있더라도, 브라우저 입장에서는 '외부'
         자원이므로 메모리가 부족해지면 언제든 원본(디스크 캐시)으로부터
         다시 디코딩할 수 있다고 판단합니다.
       * 따라서 Blob URL로 로드된 이미지보다 GPU 텍스처의 캐시 제거
         우선순위가 더 높게(High Eviction Priority) 설정됩니다.

  결론

  스크롤 시 발생하는 버벅임은 이미지를 S3에서 다시 다운로드하는 것이
  아니라, GPU 메모리에서 제거되었던 텍스처를 다시 생성하기 위해 비싼
  '디코딩' 과정을 재수행하기 때문에 발생하는 현상입니다.

  해결 방안

  S3 이미지를 브라우저가 로컬 파일처럼 '신뢰할 수 있는 리소스'로
  인식하도록 만드는 것입니다.

  방법: <img> 태그의 src에 S3 URL을 직접 할당하는 대신, 아래와 같이
  JavaScript를 통해 Blob URL로 변환하여 제공합니다.

   1. fetch API를 사용해 S3 이미지 데이터를 요청합니다.
   2. 응답(Response)을 Blob 객체로 변환합니다.
   3. URL.createObjectURL()을 사용해 해당 Blob에 대한 임시 URL을
      생성합니다.
   4. 생성된 Blob URL을 <img> 태그의 src 속성에 할당합니다.

    1 async function applyBlobUrlToImg(imgElement, imageUrl) {
    2   try {
    3     const response = await fetch(imageUrl);
    4     const imageBlob = await response.blob();
    5     const blobUrl = URL.createObjectURL(imageBlob);
    6     imgElement.src = blobUrl;
    7   } catch (error) {
    8     console.error("Error converting image to blob URL:",
      error);
    9     // 변환 실패 시 원본 URL 사용
   10     imgElement.src = imageUrl;
   11   }
   12 }
   13
   14 // 사용 예시
   15 const s3Image = document.querySelector('#my-s3-image');
   16 applyBlobUrlToImg(s3Image, s3Image.src);

  이 방식을 적용하면 S3 이미지의 GPU 텍스처 캐시 제거 우선순위가 낮아져,
   스크롤 시 부드러운 사용자 경험을 제공할 수 있을 것으로 기대합니다.

  내용 확인 부탁드립니다.

  감사합니다.
```



---


- 문제 상황:
맥북은 스크롤 로딩 지연이 있고, 아이폰은 거의 없다.
맥북이 더 사양이 좋아 보이는데 왜?
사실 아까 로컬에서 렉이 안걸렸던 이유는 아이폰과 맥의 차이인가?

# 아이폰, 맥 퍼포먼스 비교
### 아이폰의 경우:
naturalWidth (원본): 2923px
clientWidth (렌더링): 178px
devicePixelRatio: 3
5.5배 다운스케일링

  

맥북의 경우:
평균
naturalWidth (원본): 2923px
clientWidth (렌더링): 121px
devicePixelRatio: 1.100000023841858
22배 다운스케일링


결론: 맥북이 더 다운스케일링을 하는데도 렉이 걸린다.

**\[Blob 적용 결과]**  
blob을 적용하고 계속 사진을 로드하니 RESOURCE INSUFFICIENT(메모리 자원 부족) 에러가 발생하면서 결국 사진의 재로딩이 발생했음.  
브라우저 GPU가 생각보다 적어서 blob으로 해도 결국 GPU 캐시가 내려가는걸로 보임.. 

**\[신기한 현상 발견]**  
그런데 신기한 현상을 발견함. 아이폰에서는 보다시피 원본 파일로 **(썸네일 아님)** 로드해도 스크롤 로딩이 거의 없음. 성능 상 맥북이 아이폰보다 퍼포먼스가 좋아야 하는데 아이폰이 훨씬 좋음 (edited) 


해상도 차이를 고려해서 혹시 아이폰 브라우저가 사진을 임의적으로 다운스케일링 하는지도 확인해봤는데. 다운스케일링 하는 건 맞는 데 맥북도 마찬가지로 다운스케일링해서 차이가 발생하는 이유를 아직은 모르겠음.심지어 아이폰은 브라우저(혹은 OS)에서 사진을 5.5배 다운스케일링해서 알아서 최적화 했고.  
맥북은 심지어 썸네일링을 안해도 내부적으로 **22배 다운스케일링** 함.  
아래 코드로 확인함  

          `naturalWidth (원본): ${avgNatural}px`,
          `clientWidth (렌더링): ${avgClient}px`,
          `devicePixelRatio: ${window.devicePixelRatio}`,


- iOS는 **스크롤이 GPU-accelerated layer로 분리됨** → 이미지와 UI가 독립적 움직임
- macOS는 **레이어가 동기화되지 않으면 repaint 발생** → 이미지 많으면 느려짐

이 차이를 발견하긴 했는데 아직 잘 모르겠음  
결론은 아이폰에서는 스크롤 렉이 발생하지 않음..

물론 다운로드 렉을 줄이기 위해 썸네일은 무조건 도입해야 됨